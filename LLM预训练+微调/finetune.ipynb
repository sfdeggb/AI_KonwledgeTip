{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a274a9",
   "metadata": {},
   "source": [
    "# LLM 微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a11ba3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 高效参数微调（PEFT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25440300",
   "metadata": {},
   "source": [
    "微调\n",
    "微调是为了更好的适配具体的任务和任务领域，同时通过旁路小参数矩阵的注入，来实现训练资源需求的降低\n",
    "RAG检索主要是为了解决了LLM的幻觉和知识更新的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaccb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LORA\n",
    "微调步骤\n",
    "1.选择模型中需要微调的层（如Transformer模型中的自注意力层）；\n",
    "2.在这些层的权重矩阵中引入两个新的可训练矩阵A和B，它们的维度远小于原始权重矩阵；\n",
    "3.在模型的前向传播过程中，通过计算原始权重矩阵与矩阵A和B乘积的和来得到新的输出，其中矩阵A和B的乘积代表了低秩矩阵的更新；\n",
    "4.在训练过程中，只更新A和B的参数，而保持原始权重矩阵不变；\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd491afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QLORA\n",
    "\n",
    "Lora的一种改进版本，首先对要微调的模型进行4bit量化，这样做的核心目的就是为了减少显存的需求，然后在这个4bit量化之后的模型上，通过在\n",
    "需要的层上添加lora矩阵来实现，lora微调。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AdaLORA\n",
    "这也是对Lora的一种改进方式，主要是通过自适应来调整在不同层上的一个微调程度，对于有的层重要性比较高，\n",
    "就通过增加低秩矩阵的秩来实现更大程度的微调。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05907f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据集格式\n",
    "\n",
    "#单轮数据集\n",
    "{\n",
    "  \"instruction\": \"计算这些物品的总费用。 \",\n",
    "  \"input\": \"输入：汽车 - $3000，衣服 - $100，书 - $20。\",\n",
    "  \"output\": \"汽车、衣服和书的总费用为 $3000 + $100 + $20 = $3120。\"\n",
    "}\n",
    "\n",
    "# 多轮对话数据集\n",
    "[\n",
    "  {\n",
    "    \"instruction\": \"今天的天气怎么样？\",\n",
    "    \"input\": \"\",\n",
    "    \"output\": \"今天的天气不错，是晴天。\",\n",
    "    \"history\": [\n",
    "      [\n",
    "        \"今天会下雨吗？\",\n",
    "        \"今天不会下雨，是个好天气。\"\n",
    "      ],\n",
    "      [\n",
    "        \"今天适合出去玩吗？\",\n",
    "        \"非常适合，空气质量很好。\"\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "#数据集的配置\n",
    "# 在llama-factory中的dataset_info.json中的配置（配置之后微调的时候才会读到这个数据集）\n",
    "# \"数据集名称\": {\n",
    "#   \"file_name\": \"data.json\",\n",
    "#   \"columns\": {\n",
    "#     \"prompt\": \"instruction\",\n",
    "#     \"query\": \"input\",\n",
    "#     \"response\": \"output\",\n",
    "#     \"system\": \"system\",#设定对话背景或模型角色。对提升指令遵循性、控制输出风格等很重要，许多对话任务或多轮对话会用到\n",
    "#     \"history\": \"history\"\n",
    "#   }\n",
    "# }\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc61ef",
   "metadata": {},
   "source": [
    "## 提示词微调（Soft-Prompts）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf47ab",
   "metadata": {},
   "source": [
    "1.Prompt Tuning\n",
    "基本步骤\n",
    "Prompt Tuning的过程通常包括以下几个步骤：\n",
    "\n",
    "选择一个预训练模型作为基础；\n",
    "为特定任务设计或选择一个提示模板；\n",
    "将提示模板与输入数据结合，形成新的输入序列；\n",
    "在预训练模型上进行训练，只更新提示模板的参数；\n",
    "使用测试数据集评估模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Prefix-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcb7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.P-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aca79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Multitask prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4524d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de63577",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参考资料\n",
    "#[llama-factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/data_preparation.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
